{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ThJjAaw6R5g0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zzkU0JdQTDWd"
   },
   "outputs": [],
   "source": [
    "class VotingClassifier(object):\n",
    "    \"\"\"Stripped-down version of VotingClassifier that uses prefit estimators\"\"\"\n",
    "    def __init__(self, estimators, voting='hard', weights=None):\n",
    "        self.estimators = [e[1] for e in estimators]\n",
    "        self.named_estimators = dict(estimators)\n",
    "        self.voting = voting\n",
    "        self.weights = weights\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\" Predict class labels for X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        Returns\n",
    "        ----------\n",
    "        maj : array-like, shape = [n_samples]\n",
    "            Predicted class labels.\n",
    "        \"\"\"\n",
    "\n",
    "        # check_is_fitted(self, 'estimators')\n",
    "        if self.voting == 'soft':\n",
    "            maj = np.argmax(self.predict_proba(X), axis=1)\n",
    "\n",
    "        else:  # 'hard' voting\n",
    "            predictions = self._predict(X)\n",
    "            maj = np.apply_along_axis(lambda x:\n",
    "                                      np.argmax(np.bincount(x,\n",
    "                                                weights=self.weights)),\n",
    "                                      axis=1,\n",
    "                                      arr=predictions.astype('int'))\n",
    "        return maj\n",
    "\n",
    "    def _collect_probas(self, X):\n",
    "        \"\"\"Collect results from clf.predict calls. \"\"\"\n",
    "        return np.asarray([clf.predict_proba(X) for clf in self.estimators])\n",
    "\n",
    "    def _predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities for X in 'soft' voting \"\"\"\n",
    "        if self.voting == 'hard':\n",
    "            raise AttributeError(\"predict_proba is not available when\"\n",
    "                                 \" voting=%r\" % self.voting)\n",
    "        #check_is_fitted(self, 'estimators')\n",
    "        avg = np.average(self._collect_probas(X), axis=0, weights=self.weights)\n",
    "        return avg\n",
    "\n",
    "    @property\n",
    "    def predict_proba(self):\n",
    "        \"\"\"Compute probabilities of possible outcomes for samples in X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        Returns\n",
    "        ----------\n",
    "        avg : array-like, shape = [n_samples, n_classes]\n",
    "            Weighted average probability for each class per sample.\n",
    "        \"\"\"\n",
    "        return self._predict_proba\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Return class labels or probabilities for X for each estimator.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        Returns\n",
    "        -------\n",
    "        If `voting='soft'`:\n",
    "          array-like = [n_classifiers, n_samples, n_classes]\n",
    "            Class probabilities calculated by each classifier.\n",
    "        If `voting='hard'`:\n",
    "          array-like = [n_samples, n_classifiers]\n",
    "            Class labels predicted by each classifier.\n",
    "        \"\"\"\n",
    "        # check_is_fitted(self, 'estimators')\n",
    "        if self.voting == 'soft':\n",
    "            return self._collect_probas(X)\n",
    "        else:\n",
    "            return self._predict(X)\n",
    "\n",
    "    def _predict(self, X):\n",
    "        \"\"\"Collect results from clf.predict calls. \"\"\"\n",
    "        return np.asarray([clf.predict(X) for clf in self.estimators]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "-JNIUTlETFBO",
    "outputId": "6fd26b9f-5f7b-4438-e4c1-62162f5e680e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Dialect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>al igual que en el yoga artístico se compite i...</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sufrió un penal de jacquet por agarrón que el ...</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nosotros le damos la confianza que necesita cu...</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dt fernando batista hoy estuvo en el banco su ...</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>los jueces son informados si el competidor est...</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences Dialect\n",
       "0  al igual que en el yoga artístico se compite i...      AR\n",
       "1  sufrió un penal de jacquet por agarrón que el ...      AR\n",
       "2  nosotros le damos la confianza que necesita cu...      AR\n",
       "3  dt fernando batista hoy estuvo en el banco su ...      AR\n",
       "4  los jueces son informados si el competidor est...      AR"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spanish_dialects_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ETi7lGxRTE8p"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=2000, min_df=3, max_df=0.7)\n",
    "X = vectorizer.fit_transform(df['Sentences'].values).toarray()\n",
    "\n",
    "labels_map = {'AR':0, 'CO':1, 'CU':2, 'MX':3, 'PE':4, 'SV':5}\n",
    "Y = df['Dialect'].map(labels_map).tolist()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True, random_state=555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qN2PIUunTE6E",
    "outputId": "fa1f1a79-cd65-4cfc-81fc-e3dcc43b8367"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "Confusion Matrix.\n",
      " [[303  75  24  56 104  63]\n",
      " [ 47 363  47  15  64  65]\n",
      " [ 41  75 195  16  66  50]\n",
      " [ 94  56  31 155  63  52]\n",
      " [ 52  38  18  14 457  35]\n",
      " [ 40  89  30  16  44 360]]\n",
      "\n",
      "Classification Report.\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.48      0.50       625\n",
      "           1       0.52      0.60      0.56       601\n",
      "           2       0.57      0.44      0.49       443\n",
      "           3       0.57      0.34      0.43       451\n",
      "           4       0.57      0.74      0.65       614\n",
      "           5       0.58      0.62      0.60       579\n",
      "\n",
      "    accuracy                           0.55      3313\n",
      "   macro avg       0.56      0.54      0.54      3313\n",
      "weighted avg       0.55      0.55      0.55      3313\n",
      "\n",
      "\n",
      "Accuracy Score.\n",
      " 0.5532749773619077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['random_forest_classifier.sav']"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training RandomForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "text_classifier = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "text_classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Prediction on test set\n",
    "predictions = text_classifier.predict(X_test)\n",
    "\n",
    "print('Random Forest Classifier')\n",
    "print('Confusion Matrix.\\n',confusion_matrix(Y_test,predictions))\n",
    "print('\\nClassification Report.\\n',classification_report(Y_test,predictions))\n",
    "print('\\nAccuracy Score.\\n',accuracy_score(Y_test, predictions))\n",
    "\n",
    "fname = 'random_forest_classifier.sav'\n",
    "joblib.dump(text_classifier, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gVW04g6fTE3c",
    "outputId": "9460fbbf-1406-4459-f16c-cc7524614251"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Confusion Matrix.\n",
      " [[338  53  31  26 105  72]\n",
      " [ 44 386  50  18  62  41]\n",
      " [ 33  82 214  15  65  34]\n",
      " [ 84  63  29 160  78  37]\n",
      " [ 48  27  26   6 484  23]\n",
      " [ 41  72  33  13  39 381]]\n",
      "\n",
      "Classification Report.\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.54      0.56       625\n",
      "           1       0.57      0.64      0.60       601\n",
      "           2       0.56      0.48      0.52       443\n",
      "           3       0.67      0.35      0.46       451\n",
      "           4       0.58      0.79      0.67       614\n",
      "           5       0.65      0.66      0.65       579\n",
      "\n",
      "    accuracy                           0.59      3313\n",
      "   macro avg       0.60      0.58      0.58      3313\n",
      "weighted avg       0.60      0.59      0.58      3313\n",
      "\n",
      "\n",
      "Accuracy Score.\n",
      " 0.5925143374584968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['MultinomialNB_classifier.sav']"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training MultinomialNB\n",
    "text_classifier = MultinomialNB()\n",
    "text_classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Prediction on test set\n",
    "predictions = text_classifier.predict(X_test)\n",
    "\n",
    "print('Multinomial NB')\n",
    "print('Confusion Matrix.\\n',confusion_matrix(Y_test,predictions))\n",
    "print('\\nClassification Report.\\n',classification_report(Y_test,predictions))\n",
    "print('\\nAccuracy Score.\\n',accuracy_score(Y_test, predictions))\n",
    "\n",
    "fname = 'MultinomialNB_classifier.sav'\n",
    "joblib.dump(text_classifier, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n7HNu9WUTE0v",
    "outputId": "482952d9-d5cb-4982-8dab-5067fd699a40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian NB\n",
      "Confusion Matrix.\n",
      " [[177  26 171  34 143  74]\n",
      " [ 30 227 179  31  68  66]\n",
      " [ 13  11 329  20  41  29]\n",
      " [ 34  20 132 152  81  32]\n",
      " [ 19  13  97   7 457  21]\n",
      " [ 23  35 123  17  47 334]]\n",
      "\n",
      "Classification Report.\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.28      0.38       625\n",
      "           1       0.68      0.38      0.49       601\n",
      "           2       0.32      0.74      0.45       443\n",
      "           3       0.58      0.34      0.43       451\n",
      "           4       0.55      0.74      0.63       614\n",
      "           5       0.60      0.58      0.59       579\n",
      "\n",
      "    accuracy                           0.51      3313\n",
      "   macro avg       0.55      0.51      0.49      3313\n",
      "weighted avg       0.56      0.51      0.50      3313\n",
      "\n",
      "\n",
      "Accuracy Score.\n",
      " 0.5058859040144884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['GaussianNB_classifier.sav']"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training MultinomialNB\n",
    "text_classifier = GaussianNB()\n",
    "text_classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Prediction on test set\n",
    "predictions = text_classifier.predict(X_test)\n",
    "\n",
    "print('Gaussian NB')\n",
    "print('Confusion Matrix.\\n',confusion_matrix(Y_test,predictions))\n",
    "print('\\nClassification Report.\\n',classification_report(Y_test,predictions))\n",
    "print('\\nAccuracy Score.\\n',accuracy_score(Y_test, predictions))\n",
    "\n",
    "fname = 'GaussianNB_classifier.sav'\n",
    "joblib.dump(text_classifier, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ynnWQ1_ETEx_",
    "outputId": "4007eef3-cc78-417c-dfc0-016b46232ec9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "Confusion Matrix.\n",
      " [[394  51  30  41  49  60]\n",
      " [ 48 411  36  19  40  47]\n",
      " [ 44  76 232  15  43  33]\n",
      " [100  60  24 208  36  23]\n",
      " [ 58  33  19  11 475  18]\n",
      " [ 56  79  31  12  32 369]]\n",
      "\n",
      "Classification Report.\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.63      0.59       625\n",
      "           1       0.58      0.68      0.63       601\n",
      "           2       0.62      0.52      0.57       443\n",
      "           3       0.68      0.46      0.55       451\n",
      "           4       0.70      0.77      0.74       614\n",
      "           5       0.67      0.64      0.65       579\n",
      "\n",
      "    accuracy                           0.63      3313\n",
      "   macro avg       0.64      0.62      0.62      3313\n",
      "weighted avg       0.63      0.63      0.63      3313\n",
      "\n",
      "\n",
      "Accuracy Score.\n",
      " 0.6305463326290371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['svm_classifier.sav']"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training SVM\n",
    "text_classifier = SVC(probability=True)\n",
    "text_classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Prediction on test set\n",
    "predictions = text_classifier.predict(X_test)\n",
    "\n",
    "print('SVM')\n",
    "print('Confusion Matrix.\\n',confusion_matrix(Y_test,predictions))\n",
    "print('\\nClassification Report.\\n',classification_report(Y_test,predictions))\n",
    "print('\\nAccuracy Score.\\n',accuracy_score(Y_test, predictions))\n",
    "\n",
    "fname = 'svm_classifier.sav'\n",
    "joblib.dump(text_classifier, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ZiRPw70TEvI",
    "outputId": "e6b36c5d-a1f3-4bbc-f89d-f932d3d70da0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Voting Classifier\n",
      "Voting Classifier\n",
      "Confusion Matrix.\n",
      " [[385  49  33  33  71  54]\n",
      " [ 42 400  52  16  50  41]\n",
      " [ 37  74 241  12  52  27]\n",
      " [ 92  61  35 177  57  29]\n",
      " [ 48  24  27   8 487  20]\n",
      " [ 50  81  35   9  37 367]]\n",
      "\n",
      "Classification Report.\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.62      0.60       625\n",
      "           1       0.58      0.67      0.62       601\n",
      "           2       0.57      0.54      0.56       443\n",
      "           3       0.69      0.39      0.50       451\n",
      "           4       0.65      0.79      0.71       614\n",
      "           5       0.68      0.63      0.66       579\n",
      "\n",
      "    accuracy                           0.62      3313\n",
      "   macro avg       0.63      0.61      0.61      3313\n",
      "weighted avg       0.63      0.62      0.62      3313\n",
      "\n",
      "\n",
      "Accuracy Score.\n",
      " 0.6208874132206459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['voting_classifier.sav']"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Voting Classifier\n",
    "svm = joblib.load('svm_classifier.sav')\n",
    "multinomialNB = joblib.load('MultinomialNB_classifier.sav')\n",
    "gaussianNB = joblib.load('GaussianNB_classifier.sav')\n",
    "rfc = joblib.load('random_forest_classifier.sav')\n",
    "\n",
    "\n",
    "text_classifier = VotingClassifier(estimators=[('svm', svm), ('mNB', multinomialNB), ('gNB', gaussianNB), ('rfc', rfc)], voting='hard')\n",
    "print('Created Voting Classifier')\n",
    "# Prediction on test set\n",
    "predictions = text_classifier.predict(X_test)\n",
    "\n",
    "print('Voting Classifier')\n",
    "print('Confusion Matrix.\\n',confusion_matrix(Y_test,predictions))\n",
    "print('\\nClassification Report.\\n',classification_report(Y_test,predictions))\n",
    "print('\\nAccuracy Score.\\n',accuracy_score(Y_test, predictions))\n",
    "\n",
    "fname = 'voting_classifier.sav'\n",
    "joblib.dump(text_classifier, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Rkocf3hDTEsJ",
    "outputId": "c3f9f107-2c12-4082-f740-8e5aa48a6c53"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'0.22.2.post1'"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gWxPuLq4TEpB",
    "outputId": "66179859-75f2-488e-c095-ea19acc1e3db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: GaussianNB_classifier.sav (deflated 15%)\n",
      "  adding: MultinomialNB_classifier.sav (deflated 16%)\n",
      "  adding: random_forest_classifier.sav (deflated 86%)\n",
      "  adding: svm_classifier.sav (deflated 99%)\n",
      "  adding: voting_classifier.sav (deflated 92%)\n"
     ]
    }
   ],
   "source": [
    "!zip saved_models *.sav"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DM&TA-CW3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
